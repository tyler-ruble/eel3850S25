{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9\n",
    "\n",
    "- Parameter Estimation\n",
    "- Confidence Intervals for Estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Variance\n",
    "\n",
    "Let $X$ be a random variable and $b$ and $c$ constant values.\n",
    "\n",
    "1. $\\operatorname{Var}[X] = E[X^2] - (E[X])^2 \\geq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $\\operatorname{Var}[c] = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. $\\operatorname{Var}[cX + b] = c^2 Var[X]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "4. **For independent random variables** (where knowing one does not change the distribution of the others), **the variance of the sum is the sum of the variances**,\n",
    "\\begin{align*}\n",
    "\\operatorname{Var}\\left[\\sum_{i=0}^{N-1} X_i \\right] =\n",
    "\\sum_{i=0}^{N-1}  \\operatorname{Var}\\left[X_i \\right].\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Analytically:\n",
    "\n",
    "\\begin{align*}\n",
    "E[X] = \\int_0^{\\infty} x \\lambda \\exp^{-\\lambda x}~dx =\\lambda \\int_0^{\\infty} x \\exp^{-\\lambda x}~dx\n",
    "\\end{align*}\n",
    "\n",
    "Need to apply integral by parts. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Mean and Variance\n",
    "\n",
    "Let $X=\\{X_1,X_2,\\cdots, X_N\\}$ be independent observations that come from a common distribution.\n",
    "\n",
    "### Estimating the Mean\n",
    "\n",
    "Let $\\mu_X$ denote the mean of the random variables. Then $\\mu_X$ is usually estimated via the **sample mean** estimator, \n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_X = \\frac{1}{N} \\sum_{i=0}^{N-1} X_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample-mean estimator converges to the true mean if the variance of the distribution is finite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.08520843816028\n"
     ]
    }
   ],
   "source": [
    "n = 1000# number of samples\n",
    "\n",
    "X = stats.norm(loc= 120,scale= 2) # generate samples from a normal distribution with mean 120 and std 2\n",
    "Xvals =  X.rvs(n)\n",
    "sums =  np.sum(Xvals)\n",
    "avgs =  (1/n)*np.sum(Xvals)\n",
    "\n",
    "print(avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hv/nfkbddg56bqbd3ply631tttc0000gp/T/ipykernel_76673/2354233549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sample Mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of values in average'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'True Mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(1, n+1),____, label='Sample Mean')\n",
    "plt.xlabel('Number of values in average');\n",
    "plt.ylabel('Value');\n",
    "plt.plot(np.arange(1,n+1), [120]*n, label='True Mean');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples from the estimator hat u_x\n",
    "num_sims = 10_000\n",
    "avgs =np.zeros(num_sims)\n",
    "m = 10000\n",
    "for k in range(num_sims):\n",
    "    Xvals = X.rvs(m)\n",
    "    avg = np.sum(Xvals)/m\n",
    "    avgs[k]= avg\n",
    "\n",
    "expect_estimator = np.sum(avgs)/num_sims\n",
    "print(\"the expected value of the estimator\", expect_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating bias via simulation**\n",
    "\n",
    "Let's consider again what it means for the average (sample mean) to be an unbiased estimator.\n",
    "\n",
    "<!---\n",
    "\n",
    " **It does not mean that the average converges to the true mean for large $N$ -- unbiased has nothing to do with the number of samples in the data.**\n",
    "* Instead, it means that for any $N$, the expected value of the average is equal to the true mean.  \n",
    "--->\n",
    "\n",
    "We can estimate the expected value of an estimator through simulation by calculating the value of the estimator for many different random samples.\n",
    "\n",
    "Then the expected value of the estimator is the average over all of those samples.\n",
    " \n",
    "$$\n",
    "\\hat{\\mu}_X = \\frac{1}{N} \\sum_{i=0}^{N-1} X_i\n",
    "$$\n",
    " \n",
    " The expected value of $\\hat \\mu_X$:\n",
    "  \n",
    "$$\n",
    "E (\\hat{\\mu}_X )= E\\left( \\frac{1}{N} \\sum_{i=0}^{N-1} X_i\\right) \\approx \\frac{1}{n}  \\sum_{k=1}^n \\hat \\mu^k_X\n",
    "$$\n",
    "where $ \\hat{\\mu}_X = \\frac{1}{N} \\sum_{i=0}^{N-1} x^k_i$ for the $k$-th experiment with samples $[x^k_1,\\ldots, x^k_N]$\n",
    " \n",
    "\n",
    "Below is a simulation that estimates the expected value of the sample-mean estimator for $N=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10_000\n",
    "avgs =np.zeros(num_sims)\n",
    "m = 100\n",
    "\n",
    "for k in range(num_sims):\n",
    "    Xvals = X.rvs(m)\n",
    "    avg = np.sum(Xvals)/m\n",
    "    avgs[k]= avg\n",
    "\n",
    "expect_estimator = np.sum(avgs)/num_sims\n",
    "bias = expect_estimator - X.mean()\n",
    "print(\"the expected value of the estimator\", expect_estimator)\n",
    "print('The bias is'+f'{ bias : 0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10_000\n",
    "avgs =np.zeros(num_sims)\n",
    "m = 100\n",
    "vals= np.zeros(num_sims)\n",
    "\n",
    "# g(u_x)= u_x^2\n",
    "for k in range(num_sims):\n",
    "    Xvals = X.rvs(m)\n",
    "    avg = np.sum(Xvals)/m\n",
    "    avgs[k]= avg\n",
    "    vals[k]= avg**2\n",
    "\n",
    "expect_func = np.sum(vals)/num_sims\n",
    "print(\"the expected value of the function\", expect_func)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated mean of the sample-mean estimator is equal to the true mean, so this matches our theoretical result: the sample-mean estimator is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Estimating the Variance\n",
    "\n",
    "Let $\\sigma_{X}^{2}$ denote the variance of the random variables. Then there are two cases that should be considered for estimating the variance. \n",
    "\n",
    "\n",
    "**Known Mean:** First, consider the case where the mean of the random variables, $\\mu_X$, is known. Let the sample-variance estimator for this case be defined by\n",
    "\n",
    "$$\\hat{\\sigma^2_X} = \\frac{1}{N}\\sum_{i=1}^N (X_i-\\mu_X)^2.$$\n",
    "\n",
    "\n",
    "Note that the sample variance estimator depends on the mean. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As with the sample-mean estimator, let's conduct a simulation to confirm that the sample-variance estimator is unbiased.  \n",
    "$$E(\\hat{\\sigma}^2_X) = E\\left( \\frac{1}{N}\\sum_{i=1}^N (X_i-\\mu_X)^2 \\right)  \\approx \\frac{1}{n}  \\sum_{k=1}^n \\hat{\\sigma}^{2,k}_X  $$\n",
    "\n",
    "\n",
    "\n",
    "where $\\hat{\\sigma}^{2,k}_X = \\frac{1}{N} \\sum_{i=0}^{N-1} (x^k_i-\\mu_X)^2$ for the $k$-th experiment with samples $[x^k_1,\\ldots, x^k_N]$, we perform the experiment $n$ times. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10_000\n",
    "data_size = 10 # This is our N\n",
    "mu = 120 # Assume mean known\n",
    "X = stats.norm(mu, 2)\n",
    "\n",
    "varlist = np.zeros(num_sims)\n",
    "\n",
    "total_var = 0\n",
    "for sim in range(num_sims):\n",
    "    Xvals = X.rvs(data_size)\n",
    "    var = (1/data_size)*np.sum((Xvals - mu)**2)  # estimate the variance from sample\n",
    "    varlist[sim] = var\n",
    "    \n",
    "total_var  =  np.sum(varlist)\n",
    "expc_var = total_var/num_sims\n",
    "\n",
    "print('The estimated mean of the sample-variance estimator is' + f'{ expc_var: 0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Unknown Mean:** \n",
    "\n",
    "Now consider the case where the variance of the data is being estimated when the mean is unknown. If we want to apply the above sample-variance estimator, we will have to replace the true value of $\\mu_X$ with its estimate $\\hat{\\mu}_X$, giving \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2_X = \\frac{1}{N}\\sum_{i=1}^N (X_i-\\hat{\\mu}_X)^2.\n",
    "$$\n",
    "\n",
    "Let's run a simulation to check if this is an unbiased estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated mean of the sample-variance estimator is 3.60\n"
     ]
    }
   ],
   "source": [
    "num_sims = 10_000\n",
    "data_size = 10 # This is our N\n",
    "mu = 120 # Assume mean known\n",
    "X = stats.norm(mu, 2)\n",
    "\n",
    "total_var = 0\n",
    "for sim in range(num_sims):\n",
    "    Xvals = X.rvs(data_size)\n",
    "    mu_hat = Xvals.mean()\n",
    "    var =  (1/data_size)*np.sum([(xi-mu_hat)**2 for xi in Xvals])\n",
    "    total_var  += var  \n",
    "\n",
    "print('The estimated mean of the sample-variance estimator is' +\n",
    "      f'{total_var/num_sims: 0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the result biased? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCUSSION:\n",
    "\n",
    "These estimator of variance when mean is unknown is biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbiased Estimator when the sample mean is unknown\n",
    "\n",
    "Just multiply the previous estimator by a factor of $N/(N-1)$, which yields the following unbiased estimator: \n",
    "$$\n",
    "\\hat{\\sigma^2_X} = \\frac{1}{N-1}\\sum_{i=1}^N (X_i-\\hat{\\mu}_X)^2.\n",
    "$$\n",
    "\n",
    "The change in denominator is often referred to as a *degrees-of-freedom (dof) correction*.\n",
    "\n",
    "Simple interpretation:\n",
    "* we started with the number of dof equal to the size of our data ($N$)\n",
    "* used one dof in calculating the sample mean\n",
    "* there are $N-1$ dofs remaining\n",
    "\n",
    "Because a dof correction is so common in calculating the sample variance, NumPy supports passing a `ddof` parameter to `np.var()`, where `ddof` is the \"Delta Degrees of Freedom\".\n",
    "\n",
    "In other words, we don't need to pass $N-1$, we only need to pass the difference from $N$, which is `ddof=1`. \n",
    "\n",
    "Let's test this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated mean of the sample-variance estimator is 4.01\n"
     ]
    }
   ],
   "source": [
    "num_sims = 10_000\n",
    "data_size = 10\n",
    "mu = 120# Assume mean known\n",
    "X = stats.norm(mu, 2)\n",
    "\n",
    "total_var = 0\n",
    "for sim in range(num_sims):\n",
    "    Xvals = X.rvs(data_size)\n",
    "    mu_hat = Xvals.mean()\n",
    "    # var =  (1/(data_size-1))*np.sum([(xi-mu_hat)**2 for xi in Xvals])\n",
    "    var = Xvals.var(ddof = 1) # unbiased estimator for the variance.\n",
    "    total_var  += var  \n",
    "\n",
    "print('The estimated mean of the sample-variance estimator is' +\n",
    "      f'{total_var/num_sims: 0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the result biased? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "Let's introduce to distinguish between unbiased and biased variance estimators and variance estimates. \n",
    "\n",
    "Consider data $\\mathbf{x} =  \\left[ x_0, x_1, \\ldots, x_{n -1} \\right]$ with sample average $\\hat{\\mu}_X$. \n",
    "\n",
    "We will use an uppercase $S$ to indicate an estimator and a lowercase $s$ to indicate an estimate.\n",
    "\n",
    "A subscript of $n$ indicates division by $n$ and is thus a biased estimator/estimate.\n",
    "\n",
    "A subscript of $n-1$ indicates division by $n-1$ and is thus an unbiased estimator/estimate. \n",
    "\n",
    "\\begin{align*}\n",
    "S_{n}^{2} &= \\frac 1 {n} \\sum_{i=0}^{n-1} \\left( X_i - \\hat{\\mu}_X  \\right)^2, &&\\mbox{ (biased)} \\\\\n",
    "S_{n-1}^{2} &= \\frac 1 {n-1} \\sum_{i=0}^{n-1} \\left( X_i - \\hat{\\mu}_X \\right)^2 &&\\mbox{ (unbiased).}\\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Confidence Intervals for Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The parameter estimates we have considered up to this point are point estimates: they are single numerical values computed from the data.\n",
    "\n",
    "Point estimates are commonly used, but they inherently do not provide any quantification of the ambiguity or reliability of the estimate. \n",
    "\n",
    "An *interval estimate* is an alternative that provides more information:\n",
    "\n",
    "**interval estimate**\n",
    ">   Given a vector of observed values $\\mathbf{x}$ from a common distribution, an *interval estimate* for a parameter $\\theta$ is an interval $[a,b]$ that is likely to contain the true value of $\\theta$ according to some criterion.\n",
    "\n",
    "The most common interval estimates are confidence intervals for the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:\n",
    "A random sample Xvals below,   is given from a distribution with known variance $Var(X_i)=4$.   Find an approximate 95%\n",
    " confidence interval for the mean of the underlying distribution $X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvals= np.array([119.3963636 , 123.223853  , 120.61138011, 116.25379408,\n",
    "       116.2317848 , 124.08760236, 115.6569442 , 121.02301463,\n",
    "       118.21025603, 122.28635709]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "1. first step, let's compute the distance d such that $[\\hat{ u}_X -d, \\hat{ u}_X+d]$ contains the true mean $\\mu_X$ with a high probability of 95\\%.\n",
    "\n",
    "Recall in lecture, we obtain $d \\ge  Q(\\alpha/2) \\sqrt{\\frac{\\sigma^2}{N}}$ where $Q$ is the survival function of the Standard Gaussian distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N =len(Xvals)\n",
    "varX = 4 # this is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9599639845400545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G0= stats.norm() # this is a standard gaussian with mean 0 and var 1\n",
    "G0.isf(alpha/2) # the Q(\\alpha/2) part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = G0.isf(alpha/2) * np.sqrt(varX/N)\n",
    "# this is the distance d to be used to construct the upper and lower bounds for confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second step, after calculating the distance d, we can then compute the confidence interval using the sampled value of $\\hat{\\mu}_X$ and the distance d. Note that d is invariant from the samples. It only depends on the variance of the underlying RV. and the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval is  [118.45854492700671, 120.93772505622495]\n"
     ]
    }
   ],
   "source": [
    "CI = [Xvals.mean()-d, Xvals.mean()+d]\n",
    "print(\"The 95% confidence interval is \", CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the remainder is a different way to compute the confidence interval. skipping it for now. we will continue after the spring break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119.3963636 , 123.223853  , 120.61138011, 116.25379408,\n",
       "       116.2317848 , 124.08760236, 115.6569442 , 121.02301463,\n",
       "       118.21025603, 122.28635709])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_size = 10 # This is our N\n",
    "X = stats.norm(120, 2)\n",
    " \n",
    "# generate samples from the random variable.\n",
    "Xvals = X.rvs(data_size)\n",
    "Xvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sims = 100_00\n",
    "\n",
    "mean_est =  \n",
    "Y = stats.norm(mean_est,  )  # fill out, what is the variance of the mean estimate? given we know the variance of X.\n",
    "Y.interval(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Confidence Intervals for Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals are easily generated for any parameter estimates by using bootstrap sampling.\n",
    "\n",
    "To generate a $c$% confidence interval, the bootstrap distribution of the estimator is generated, and then a region containing the center $c$% of the probability is determined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the upper bound.\n",
    "\n",
    "Y.isf(0.025) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap to compute a confidence interval\n",
    " When the underlying distribution is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this with an example.   The code below takes data and a confidence interval and provides a point estimate and a confidence interval for the mean of the distribution of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean_CI(x, C):\n",
    "\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate percentiles for each edge of the CI\n",
    "    alpha =  \n",
    "    \n",
    "    avg =  \n",
    "    \n",
    "    # Now do bootstrap sampling\n",
    "    # Start by specifying the number of bootstrap values to simulate\n",
    "    num_bs_sims = 1000\n",
    "    \n",
    "    # Create an array of zeros to store the bootstrap values\n",
    "    bs_averages = np.zeros(num_bs_sims)\n",
    "    \n",
    "    for bs_sim in range(num_bs_sims):\n",
    "    #Complete this part\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Now find the values that define the C%  \n",
    "    percentiles = \n",
    "    \n",
    "    print(f'The mean estimate is {avg:.2f}')\n",
    "    print(f'A {C}% confidence interval for the average is [{percentiles[0]: .2f}, {percentiles[1]:.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the 90%, 95%, and 99% confidence intervals for the mean estimate of a small example data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([ 1, 1.2, 1.4, 1.2, 1, 1.2, 1.5, 1.45, 1.05, 1.65, 1.8])\n",
    "find_mean_CI(x, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_mean_CI(x, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_mean_CI(x, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**REMINDER**\n",
    "\n",
    "Let's remind ourselves of what a $c$% confidence interval means:\n",
    "* it does **not** mean that there is a $c$% probability that a particular confidence interval contains the true mean\n",
    "* it means that over the long run, the true mean would lie in $c$% of the confidence intervals that are generated according to this procedure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 2000\n",
    "data_size = 10\n",
    "\n",
    "# True mean\n",
    "mu = 1\n",
    "\n",
    "X = stats.norm(mu,2 )\n",
    "\n",
    "num_miss_true_mean = 0\n",
    "for sim in range(num_sims):\n",
    "    Xvals =  \n",
    "\n",
    "    # Now do bootstrap sampling with this sample Xvals.\n",
    "    num_bs_sims = 1000\n",
    "    bs_averages = np.zeros(num_bs_sims)\n",
    "    for bs_sim in range(num_bs_sims):\n",
    "         # todo \n",
    "    percentiles =  # todo\n",
    "    if : # condition when the true mean is not contained by the interval \n",
    "        num_miss_true_mean += 1\n",
    "\n",
    "print('The probability a bootstrap CI does not contain the true mean is' \n",
    "      + f'{num_miss_true_mean/num_sims : 0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For data sample sizes of less than approximately 100, the $c$% confidence intervals generated via bootstrap sampling are generally **not wide enough** to achieve the specified confidence. Let's illustrate this with an experiment:\n",
    "\n",
    "\n",
    "The simulation below draws a data sample of 10 random values from a Normal (1, 2) distribution.\n",
    "* For each sample, the sample mean is calculated, and bootstrap sampling is used to generate a 95% confidence interval for the sample mean.\n",
    "* This process is repeated to find the sample mean and the confidence interval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the long run, we expect at least 5% of confidence intervals to not contain the true mean.\n",
    "\n",
    "However, the bootstrap estimator for CIs is not conservative enough for small data.\n",
    "\n",
    "The following simulation provides a more accurate estimate of the probability that the CI contains the true mean by running 2,000 simulations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's repeat this experiment with a larger set of samples for bootstrap sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a table that shows the probability[^ci_probs] that a bootstrap sample does not contain the true mean for this distribution as a function of $N$:\n",
    "\n",
    "| Data Size ($N$) | Probability CI does not contain true mean |\n",
    "| :-: | :-: |\n",
    "| 5 | 16.3% |\n",
    "| 10 | 10.0% |\n",
    "| 25 | 6.9% |\n",
    "| 50 | 5.9% |\n",
    "| 75 | 5.6% |\n",
    "| 100 | 5.5% |\n",
    "\n",
    "\n",
    "(If you have smaller data, more sophisticated methods are available -- see the refs in the textbook!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confidence Intervals for Mean Estimate with Unknown Data Variance\n",
    "\n",
    "If the standard deviation or variance of the distribution is not known, then we must estimate it. We will use the unbiased variance estimator, \n",
    "\\begin{align*}\n",
    "S_{n-1}^2 = \\frac{1}{n-1}\\sum_{i=0}^{n-1} \\left(X_i-\\hat{\\mu}_X \\right)^2.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that if $\\hat{\\mu}_X$ is Normal( $\\mu_X, \\sigma_X)$ , then \n",
    "$$\n",
    "\\frac{ X  - \\mu_X}{\\sigma_X} \\sim \\mbox{Normal}(0,1).\n",
    "$$\n",
    "\n",
    "If we have to replace the true variance by its estimate, then the distribution changes. Using the unbiased variance estimator instead of the true variance, the distribution of\n",
    "\n",
    "$$\n",
    "\\frac{\\hat{\\mu}-\\mu_X }{S_{n-1}/\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "has a **Student’s $t$-distribution with $\\nu = n-1$ degrees of freedom (dof)**, $t_\\nu$.\n",
    "\n",
    "(Like a Gaussian, but more spread out!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Student's $t$ Random Variable\n",
    "\n",
    "The Student's $t$ random variable arises when estimating the mean $\\mu$ of data from a Normal distribution for which the variance $\\sigma^2$ is not known. \n",
    "\n",
    "The distribution takes its name from a paper by William Sealy Gosset that was published under the pen name *Student*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "**Student's $t$ random variable**\n",
    ">   If $T$ is a Student's $t$ random variable with $\\nu$ degrees of freedom, the pdf is\n",
    ">   \\begin{align*}\n",
    "    f(t)=\\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu \\pi}  \\Gamma\\left(\\frac{\\nu}{2}\\right)}\\left(1+\\frac{t^{2}}{\\nu}\\right)^{-(\\nu+1) / 2}.\n",
    "    \\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\nu \\rightarrow \\infty$, the Student's $t$ random variable converges to a normal random variable.\n",
    "\n",
    "\n",
    "The degree of freedom(dof) in a student's t distribution is the number of samples.\n",
    "    \n",
    "We can use SciPy.stats to create a standard Student's $t$ distribution by using `stats.t(dof)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows the pdf of Student's $t$ random variables with different degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "t = np.linspace(-6, 6, 121)\n",
    "for d in [1, 2, 4, 16]:\n",
    "    T = # todo\n",
    "    plt.plot(t, T.pdf(t), label=str(d) + \" dof\")\n",
    "\n",
    "N = # todo\n",
    "plt.plot(t, N.pdf(t), color=\"k\", label=\"Normal\")\n",
    "plt.legend()\n",
    "plt.title(\n",
    "    \"Densities of Student's $t$ random variables\\nwith different degrees of freedom\"\n",
    ")\n",
    "plt.xlabel(\"$t$\")\n",
    "plt.ylabel(\"$f_T(t)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the Student's $t$ random variable is similar to a standard normal random variable except that more of its probability density is spread out away from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate a SciPy distribution for a Student's $t$ variable of this form by setting the following parameters:\n",
    "* The `df` parameter is set to the number of degrees of freedom, $\\nu=n-1$\n",
    "* The `loc` parameter is set to the true mean, $\\mu_X$, and\n",
    "* The `scale` parameter  is set to the **sample** standard error of the mean (SSEM), which is obtained from the SEM equation by replacing the standard deviation with its unbiased estimate, yielding $s_{n-1}= s_{n-1}/\\sqrt{N}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sample data\n",
    "x = [-9, -4, 1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the SSEM can be computed from the data using the `stats.sem()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_t ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will often be working with a $t$ variable with mean 0. If we have data in a variable `x`, then we can generate a SciPy $t$-distribution as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=stats.t(#to fill out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average value is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the true mean were 0, the probability of seeing such a large value of the mean could be computed using the `T` object as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create analytical confidence intervals with the standard deviation estimated from the data, we can again find a region $\\left(\\hat{\\mu}_X -d, \\hat{\\mu}_X+d \\right]$ that satisfies\n",
    "\\begin{align*}\n",
    " P\\left(  \\hat{\\mu}_X  - \\mu > d \\right) = \\alpha,\n",
    "\\end{align*}\n",
    "where $\\alpha = (1-c)/2$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO\n",
    "# The data\n",
    "x0= np.array([-0.41957876,  0.96561764,  1.63882274, -3.53066214, -1.75490733,\n",
    "        4.89996147, -0.12762015, -0.68747518,  1.44907716,  0.21724457])\n",
    "\n",
    "n0=len(x0)\n",
    "\n",
    "# Set C and calculate alpha\n",
    "C= \n",
    "alpha = \n",
    "\n",
    "# Calculate the SSEM\n",
    "sigma_t =  \n",
    "\n",
    "\n",
    "# Now create the scaled Student's t distribution object using SciPy\n",
    "T0 =stats.t(df= ,scale =  )\n",
    "\n",
    "# And now find the value of d using the inverse survival function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can directly use the confidence interval for 0.95 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the confidence interval estimated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the confidence intervals produced using the Student's $t$ distribution are very similar to those produced by bootstrap sampling because the width of the confidence interval is now determined from the data.\n",
    "\n",
    "Data samples 11 and 15 do not include the true mean for the analytical model with estimated variance.\n",
    "\n",
    "Just like the bootstrap confidence intervals, the Student's $t$ model does not provide  confidence intervals that are conservative enough when the number of samples is small.\n",
    "\n",
    "Various correction factors are available in the literature to provide better confidence intervals for small data samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc-showcode": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
